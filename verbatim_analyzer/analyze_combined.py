# analyze_combined.py
import streamlit as st
import pandas as pd
import plotly.express as px
import utils
from column_mapper import load_csv_with_mapping
from sidebar_options import get_sidebar_options
from report_utils import generer_et_afficher_rapport
from verbatim_analyzer.marketing_analyzer import extract_marketing_clusters_with_openai, associer_sous_themes_par_similarity
from streamlit_tree_select import tree_select
from verbatim_analyzer.pricing import estimate_average_chars, render_llm_selector, compute_usage_cost

def run():
    st.title("üß© Analyse compl√®te des verbatims")
    st.markdown("""
    Bienvenue dans le module **Analyse combin√©e**.  
    Suivez les √©tapes ci-dessous pour explorer vos verbatims selon les approches **Marketing** ou **IA Rating**.
    """)

    # === √âtape 1 : Chargement fichier ===
    st.header("üìÇ √âtape 1 : Import du fichier")
    uploaded_file = st.file_uploader("T√©l√©versez un fichier CSV", type="csv")

    if uploaded_file is None:
        st.info("En attente d‚Äôun fichier CSV‚Ä¶")
        st.stop()

    df = load_csv_with_mapping(
        uploaded_file,
        required_fields=["Verbatim public"],
        optional_fields=["Verbatim priv√©", "Note globale avis 1"],
        key_prefix="combined",
    )

    st.success(f"‚úÖ {len(df)} lignes charg√©es apr√®s mapping des colonnes")

    if "Verbatim public" not in df.columns:
        st.error("‚ùå Merci d'associer une colonne au champ obligatoire 'Verbatim public'.")
        st.stop()

    df["Verbatim complet"] = df["Verbatim public"].fillna("") + " " + df.get("Verbatim priv√©", "").fillna("")

    verbatims_full = df["Verbatim complet"].fillna("").astype(str)
    avg_chars_per_verbatim = estimate_average_chars(verbatims_full.tolist())

    # === √âtape 2 : Choix du mode d‚Äôanalyse ===
    st.header("‚öôÔ∏è √âtape 2 : Choisissez le mode d‚Äôanalyse")
    mode = st.radio(
        "Quelle approche souhaitez-vous utiliser ?",
        ["Analyse Marketing (note client)", "Analyse IA (note g√©n√©r√©e automatiquement)"],
        horizontal=True
    )

    options = get_sidebar_options(
        uploaded_file,
        verbatim_count=len(df),
        avg_chars_per_verbatim=avg_chars_per_verbatim,
    )
    if options.get("use_openai"):
        st.sidebar.info(
            f"LLM s√©lectionn√© : **{options['llm_model']}**\n\n"
            f"Co√ªt estim√© : ${options['llm_input_cost']:.4f} /1k in ¬∑ ${options['llm_output_cost']:.4f} /1k out"
        )

    with st.expander("‚öôÔ∏è Choix du LLM & co√ªts OpenAI", expanded=options.get("use_openai", False)):
        chosen_model, in_cost, out_cost = render_llm_selector("OpenAI")
        options["llm_model"] = chosen_model
        options["llm_input_cost"] = in_cost
        options["llm_output_cost"] = out_cost

    # === √âtape 3 : Param√©trage & Extraction des th√®mes ===
    if st.button("üîÑ R√©-extraire les clusters via OpenAI"):
        if "themes_extraits" in st.session_state:
            del st.session_state["themes_extraits"]
        st.rerun()

    st.header("üß† √âtape 3 : D√©finition des th√®mes")
    col1, col2 = st.columns(2)

    with col1:
        use_openai = st.toggle("Utiliser OpenAI pour extraire les clusters", options["use_openai"])
    with col2:
        nb_clusters = st.slider("Nombre de clusters (si OpenAI)", 3, 15, options["nb_clusters"])

    if not use_openai:
        st.session_state.pop("openai_usage_summary", None)
        st.session_state.pop("sample_metadata", None)
        st.session_state.pop("sampled_verbatims", None)

    sample_col1, sample_col2 = st.columns([2, 1])
    with sample_col1:
        sample_size = st.slider(
            "Verbatims al√©atoires envoy√©s √† OpenAI",
            min_value=1,
            max_value=max(1, len(df)),
            value=options["cluster_sample_size"],
            disabled=not use_openai,
            help="S√©lectionnez combien de verbatims seront tir√©s al√©atoirement pour g√©n√©rer les th√®mes.",
        )
    with sample_col2:
        st.metric(
            "Co√ªt estim√© entr√©e",
            f"${options['estimated_openai_cost']:.4f}",
            help="Bas√© sur la longueur moyenne observ√©e et le pricing OpenAI s√©lectionn√©",
        )

    options["cluster_sample_size"] = sample_size
    st.session_state["cluster_sample_size"] = sample_size

    trigger_extraction = st.button(
        "üöÄ Lancer l'extraction des clusters via OpenAI",
        disabled=not use_openai,
        help="Cliquez apr√®s avoir choisi la taille de l'√©chantillon pour d√©marrer l'appel OpenAI.",
    )

    themes = []
    sampled_verbatims = st.session_state.get("sampled_verbatims", [])
    sample_metadata = st.session_state.get("sample_metadata", {})
    usage_summary = st.session_state.get("openai_usage_summary")

    # üîÅ Si on a d√©j√† des th√®mes extraits en m√©moire, on les r√©utilise
    if "themes_extraits" in st.session_state:
        themes = st.session_state["themes_extraits"]
        sampled_verbatims = st.session_state.get("sampled_verbatims", sampled_verbatims)
        sample_metadata = st.session_state.get("sample_metadata", sample_metadata)
        usage_summary = st.session_state.get("openai_usage_summary", usage_summary)

    # ‚öôÔ∏è Extraction seulement si OpenAI activ√© ET sur action explicite
    elif use_openai and trigger_extraction:
        with st.spinner("Extraction via OpenAI en cours..."):
            try:
                texts_public = df["Verbatim public"].astype(str).tolist()
                texts_private = df["Verbatim priv√©"].astype(str).tolist() if "Verbatim priv√©" in df.columns else [""] * len(df)
                themes, sampled_verbatims, sample_metadata, usage = extract_marketing_clusters_with_openai(
                    texts_public,
                    texts_private,
                    nb_clusters,
                    model_name=options["llm_model"],
                    sample_size=options["cluster_sample_size"],
                    return_sample=True,
                )
                usage_summary = compute_usage_cost(usage, options["llm_input_cost"], options["llm_output_cost"])
                st.session_state["themes_extraits"] = themes
                st.session_state["sampled_verbatims"] = sampled_verbatims
                st.session_state["sample_metadata"] = sample_metadata
                st.session_state["openai_usage_summary"] = usage_summary
                st.success(
                    f"‚úÖ Clusters extraits automatiquement (√©chantillon de {options['cluster_sample_size']} verbatims)"
                )
                st.caption(
                    f"Moyenne observ√©e : ~{avg_chars_per_verbatim} caract√®res/verbatim sur {len(df)} verbatims."
                )
                with st.expander("üìë Contexte des verbatims envoy√©s √† OpenAI", expanded=False):
                    st.markdown(
                        f"{len(sampled_verbatims)} verbatims tir√©s al√©atoirement sur {len(df)} "
                        "ont √©t√© transmis √† l'API pour g√©n√©rer les th√®mes."
                    )
                    st.dataframe(pd.DataFrame({"Verbatims √©chantillonn√©s": sampled_verbatims}))
                st.rerun()
            except Exception as e:
                st.error(f"Erreur OpenAI : {e}")
                st.stop()
    elif use_openai and not trigger_extraction:
        st.info("Choisissez la taille de l'√©chantillon puis lancez l'extraction OpenAI.")

    else:
        user_themes = st.text_area("Th√®mes manuels (JSON ou CSV)").strip()
        if not user_themes:
            st.warning("‚ö†Ô∏è Fournissez une liste de th√®mes manuelle ou activez OpenAI.")
            st.stop()
        try:
            themes = pd.read_json(user_themes).to_dict(orient="records")
        except Exception:
            themes = [{"theme": t.strip(), "subthemes": []} for t in user_themes.split(",") if t.strip()]
        st.success(f"‚úÖ {len(themes)} th√®mes charg√©s manuellement")


    if sampled_verbatims:
        with st.expander("üìë Contexte des verbatims envoy√©s √† OpenAI", expanded=False):
            sampling_hint = "Tirage al√©atoire" if sample_metadata.get("randomized", False) else "Tous les verbatims ont √©t√© utilis√©s"
            st.markdown(
                f"{sampling_hint} : {len(sampled_verbatims)} verbatims sur {sample_metadata.get('total', len(df))}."
            )
            if sample_metadata.get("indices"):
                indices_preview = ", ".join(map(str, sample_metadata["indices"][:50]))
                if len(sample_metadata["indices"]) > 50:
                    indices_preview += " ‚Ä¶"
                st.caption(f"Indices tir√©s avec random.sample : {indices_preview}")
            st.dataframe(pd.DataFrame({
                "Index original": sample_metadata.get("indices", list(range(len(sampled_verbatims)))),
                "Verbatims √©chantillonn√©s": sampled_verbatims
            }))

    if usage_summary:
        with st.expander("üì° Consommation r√©elle OpenAI", expanded=False):
            st.metric("Tokens entr√©e", f"{usage_summary['prompt_tokens']:,}")
            st.metric("Tokens sortie", f"{usage_summary['completion_tokens']:,}")
            st.metric("Co√ªt total estim√©", f"${usage_summary['total_cost']:.4f}")
            st.caption(
                f"D√©tail : entr√©e ${usage_summary['input_cost']:.4f} ¬∑ sortie ${usage_summary['output_cost']:.4f} "
                f"({usage_summary['total_tokens']} tokens cumul√©s)."
            )

    # --- Modification / Ajout de clusters ---
    st.divider()
    st.markdown("### ‚úèÔ∏è Modification / Ajout de clusters")

    # Ajouter un nouveau th√®me
    with st.expander("‚ûï Ajouter un nouveau th√®me"):
        new_theme = st.text_input("Nom du nouveau th√®me")
        if st.button("Ajouter le th√®me"):
            if new_theme and all(t["theme"] != new_theme for t in themes):
                themes.append({"theme": new_theme, "subthemes": []})
                st.session_state["themes_extraits"] = themes
                st.success(f"Th√®me **{new_theme}** ajout√© ‚úÖ")
                st.rerun()

    # Ajouter un sous-th√®me √† un th√®me existant
    with st.expander("‚ûï Ajouter un sous-th√®me √† un th√®me existant"):
        theme_choice = st.selectbox("S√©lectionnez le th√®me parent", [t["theme"] for t in themes])
        new_sub = st.text_input("Nom du nouveau sous-th√®me")
        new_keywords = st.text_input("Mots-cl√©s associ√©s (s√©par√©s par une virgule)")
        if st.button("Ajouter le sous-th√®me"):
            if new_sub:
                keywords_list = [kw.strip() for kw in new_keywords.split(",") if kw.strip()]
                for t in themes:
                    if t["theme"] == theme_choice:
                        t.setdefault("subthemes", []).append({"label": new_sub, "keywords": keywords_list})
                        break
                st.session_state["themes_extraits"] = themes
                st.success(f"Sous-th√®me **{new_sub}** ajout√© √† **{theme_choice}** ‚úÖ")
                st.rerun()

    # Modifier un th√®me existant
    with st.expander("‚úèÔ∏è Renommer un th√®me existant"):
        if themes:
            theme_to_edit = st.selectbox("Th√®me √† renommer", [t["theme"] for t in themes], key="theme_to_edit")
            new_theme_name = st.text_input("Nouveau nom du th√®me", value=theme_to_edit)
            if st.button("Mettre √† jour le th√®me"):
                if new_theme_name.strip():
                    for t in themes:
                        if t["theme"] == theme_to_edit:
                            t["theme"] = new_theme_name.strip()
                            break
                    st.session_state["themes_extraits"] = themes
                    st.success(f"Th√®me renomm√© en **{new_theme_name}** ‚úÖ")
                    st.rerun()
        else:
            st.info("Aucun th√®me √† modifier.")

    # Modifier un sous-th√®me ou ses mots-cl√©s
    with st.expander("üõ†Ô∏è Modifier un sous-th√®me ou ses mots-cl√©s"):
        if themes and any(t.get("subthemes") for t in themes):
            parent_theme = st.selectbox("Th√®me contenant le sous-th√®me", [t["theme"] for t in themes])
            subthemes = next((t.get("subthemes", []) for t in themes if t["theme"] == parent_theme), [])
            if subthemes:
                labels = [s.get("label") if isinstance(s, dict) else str(s) for s in subthemes]
                sub_to_edit = st.selectbox("Sous-th√®me √† modifier", labels)
                current = next((s for s in subthemes if (s.get("label") if isinstance(s, dict) else str(s)) == sub_to_edit), None)
                current_keywords = ", ".join(current.get("keywords", [])) if isinstance(current, dict) else ""
                new_label = st.text_input("Nouveau nom du sous-th√®me", value=sub_to_edit)
                new_keywords_value = st.text_area("Mots-cl√©s (s√©par√©s par des virgules)", value=current_keywords)
                if st.button("Mettre √† jour le sous-th√®me"):
                    if new_label.strip():
                        updated_keywords = [kw.strip() for kw in new_keywords_value.split(",") if kw.strip()]
                        for t in themes:
                            if t["theme"] == parent_theme:
                                updated_subthemes = []
                                for s in t.get("subthemes", []):
                                    label = s.get("label") if isinstance(s, dict) else str(s)
                                    if label == sub_to_edit:
                                        updated_subthemes.append({"label": new_label.strip(), "keywords": updated_keywords})
                                    else:
                                        updated_subthemes.append(s)
                                t["subthemes"] = updated_subthemes
                                break
                        st.session_state["themes_extraits"] = themes
                        st.success(f"Sous-th√®me mis √† jour : **{new_label}** ‚úÖ")
                        st.rerun()
            else:
                st.info("Aucun sous-th√®me pour ce th√®me.")
        else:
            st.info("Aucun sous-th√®me √† modifier.")

    # --- Arborescence interactive ---
    st.divider()
    st.markdown("### üå≥ Arborescence des clusters d√©tect√©s / d√©finis")

    def convertir_en_tree_data(themes):
        data = []
        for t in themes:
            children = []
            for s in t.get("subthemes", []):
                label = s.get("label") if isinstance(s, dict) else s
                keywords = s.get("keywords", []) if isinstance(s, dict) else []
                keyword_hint = f" ‚Äî mots-cl√©s: {', '.join(keywords)}" if keywords else ""
                children.append({
                    "label": f"{label}{keyword_hint}",
                    "value": f"{t['theme']}::{label}"
                })
            data.append({
                "label": t.get("theme", "Th√®me sans nom"),
                "value": t.get("theme", "Th√®me sans nom"),
                "children": children
            })
        return data

    tree_data = convertir_en_tree_data(themes)

    selected_nodes = tree_select(
        tree_data,
        "S√©lectionnez les th√®mes et sous-th√®mes √† retenir",
        key="cluster_tree"
    )

    if sampled_verbatims:
        with st.expander("üìë Contexte de l'√©chantillon OpenAI", expanded=False):
            st.markdown(
                f"√âchantillon al√©atoire : {len(sampled_verbatims)} verbatims envoy√©s √† l'API "
                f"sur {len(df)} disponibles."
            )
            st.dataframe(pd.DataFrame({"Verbatims √©chantillonn√©s": sampled_verbatims}))

    if selected_nodes and selected_nodes.get("checked"):
        st.session_state["selected_clusters"] = selected_nodes["checked"]
        st.success(f"üìÇ Clusters valid√©s : {', '.join(st.session_state['selected_clusters'])}")
    else:
        st.info("üü° Aucun cluster valid√© dans l‚Äôarbre.")

    def filtrer_themes(themes, selection):
        selection_set = set(selection or [])
        filtres = []
        for t in themes:
            theme_name = t.get("theme", "")
            subthemes = []
            for s in t.get("subthemes", []):
                label = s.get("label") if isinstance(s, dict) else s
                value = f"{theme_name}::{label}" if label else theme_name
                if value in selection_set:
                    subthemes.append(s)
            if theme_name in selection_set:
                filtres.append(t)
            elif subthemes:
                filtres.append({"theme": theme_name, "subthemes": subthemes})
        return filtres

    themes_selectionnes = filtrer_themes(themes, st.session_state.get("selected_clusters", []))

    # Aper√ßu du JSON final r√©ellement utilis√©
    with st.expander("üìú JSON final des th√®mes s√©lectionn√©s"):
        if themes_selectionnes:
            st.json(themes_selectionnes)
        else:
            st.info("Aucun cluster s√©lectionn√© pour le moment.")

    # üö¶ Blocage tant que rien n‚Äôest s√©lectionn√©
    if "selected_clusters" not in st.session_state or not st.session_state["selected_clusters"]:
        st.warning("‚ö†Ô∏è Vous devez valider au moins un cluster avant de continuer.")
        st.stop()



    # === √âtape 4 : Calcul des notes ===
    st.header("üí¨ √âtape 4 : Calcul des notes")
    if mode.startswith("Analyse IA"):
        st.info("Les notes sont g√©n√©r√©es automatiquement par IA (1 √† 5)")
        df["Note IA"] = df["Verbatim public"].astype(str).apply(utils.calculer_note_ia)
        note_col = "Note IA"
    else:
        if "Note globale avis 1" not in df.columns:
            st.error("‚ùå Le fichier doit contenir une colonne 'Note globale avis 1'.")
            st.stop()
        note_col = "Note globale avis 1"

    st.success(f"‚úÖ Notes pr√™tes ({note_col})")

    # === √âtape 5 : Association sous-th√®mes ===
    st.write("DEBUG options =", options)

    # Gestion de plusieurs formats possibles de retour
    if isinstance(options, dict):
        model_choice = options.get("model_choice", "MiniLM")
        seuil_similarite = options.get("seuil_similarite", 0.75)
    elif isinstance(options, list):
        # Si c‚Äôest une liste de dictionnaires
        if len(options) > 0 and isinstance(options[0], dict):
            model_choice = options[0].get("model_choice", "MiniLM")
            seuil_similarite = options[0].get("seuil_similarite", 0.75)
        else:
            # Valeurs par d√©faut si c‚Äôest une liste simple
            model_choice, seuil_similarite = "MiniLM", 0.75
    else:
        model_choice, seuil_similarite = "MiniLM", 0.75

    # Choix du mod√®le selon l‚Äôoption
    model_name = "all-MiniLM-L6-v2" if model_choice == "MiniLM" else "bert-base-nli-mean-tokens"

    # Utiliser uniquement les clusters valid√©s pour la suite
    themes_utilises = themes_selectionnes if themes_selectionnes else themes
    st.session_state["themes_valides"] = themes_utilises

    # Association des sous-th√®mes
    df_enriched = associer_sous_themes_par_similarity(
        df,
        themes=themes_utilises,
        text_col="Verbatim complet",
        model_name=model_name,
        seuil_similarite=seuil_similarite
    )
    subtheme_cols = [c for c in df_enriched.columns if "::" in c]
    if not subtheme_cols:
        st.warning("‚ö†Ô∏è Aucun sous-th√®me d√©tect√©.")
        st.stop()

    # === √âtape 6 bis : V√©rification des incoh√©rences ===
    st.header("üß© √âtape 6 bis : V√©rification des incoh√©rences s√©mantiques")

    if st.toggle("Activer la d√©tection des incoh√©rences", value=False):
        with st.spinner("üîç V√©rification des incoh√©rences en cours..."):
            incoherences = utils.verifier_coherence_semantique(
                df_enriched, subtheme_cols, seuil=0.3, alpha=0.7
            )

        if incoherences.empty:
            st.success("‚úÖ Aucune incoh√©rence d√©tect√©e.")
        else:
            st.warning(f"‚ö†Ô∏è {len(incoherences)} incoh√©rences d√©tect√©es.")
            st.dataframe(incoherences)

            # Construction de la matrice finale
            matrice_finale = utils.construire_matrice_finale(df_enriched, incoherences, subtheme_cols)
            st.markdown("### üìê Matrice finale (avec d√©cisions)")
            st.dataframe(matrice_finale)

            # Suppression des incoh√©rences dans df_enriched
            avant = len(df_enriched)
            for _, row in incoherences.iterrows():
                verb = row["Verbatim"]
                sous_theme = row["Sous-th√®me"]
                if row["Decision"] in ["‚ö†Ô∏è Suspect", "Non retenue"]:
                    df_enriched.loc[df_enriched["Verbatim complet"] == verb, sous_theme] = pd.NA
            df_enriched = df_enriched[df_enriched[subtheme_cols].notna().any(axis=1)]
            apres = len(df_enriched)

            st.info(f"üßπ Nettoyage : {avant - apres} verbatims incoh√©rents supprim√©s ({apres} restants).")

            # Export optionnel
            csv_incoh = utils.preparer_csv_export(incoherences, "incoherences_detectees.csv")
            st.download_button(
                "‚¨áÔ∏è T√©l√©charger les incoh√©rences",
                data=csv_incoh,
                file_name="incoherences_detectees.csv",
                mime="text/csv"
            )

        st.success("‚úÖ Nettoyage termin√©, passage √† la visualisation possible.")



    # === √âtape 6 : Visualisations ===
    st.header("üìä √âtape 6 : Visualisation des r√©sultats")
    tabs = st.tabs(["üìà Statistiques", "üí¨ Verbatims", "ü•ß R√©partition", "üßæ Rapport"])

    with tabs[0]:
        st.subheader("Moyenne des notes par sous-th√®me")
        df_melted = df_enriched[[note_col] + subtheme_cols].melt(id_vars=note_col, var_name="Sous-th√®me", value_name="Assoc").dropna()
        stats = df_melted.groupby("Sous-th√®me")[note_col].agg(["count", "mean"]).sort_values("mean", ascending=False)
        st.dataframe(stats)
        fig = px.bar(stats, x=stats.index, y="mean", title="Moyenne des notes par sous-th√®me")
        st.plotly_chart(fig, use_container_width=True)

    with tabs[1]:
        st.subheader("Exemples de verbatims")
        for col in subtheme_cols[:5]:
            subset = df_enriched[df_enriched[col].notna()].head(3)
            st.markdown(f"**{col}**")
            for _, row in subset.iterrows():
                st.markdown(f"- {row['Verbatim public']} ({note_col}: {row[note_col]})")

    with tabs[2]:
        st.subheader("R√©partition des sous-th√®mes")
        counts = df_enriched[subtheme_cols].notna().sum().reset_index()
        counts.columns = ["Sous-th√®me", "Occurrences"]
        fig_pie = px.pie(counts, names="Sous-th√®me", values="Occurrences", title="R√©partition des verbatims par sous-th√®me")
        st.plotly_chart(fig_pie, use_container_width=True)

    with tabs[3]:
        if st.button("üìù G√©n√©rer le rapport complet"):
            generer_et_afficher_rapport(
                stats,
                titre=f"Rapport synth√®se - {mode}",
                filename=f"rapport_{'ia' if 'IA' in mode else 'marketing'}.pdf"
            )

    # === √âtape 7 : Export CSV ===
    st.header("‚¨áÔ∏è √âtape 7 : Export des r√©sultats")
    csv_bytes = utils.preparer_csv_export(df_enriched, f"resultats_{'ia' if 'IA' in mode else 'marketing'}_fusion.csv")
    st.download_button("T√©l√©charger les r√©sultats", data=csv_bytes, file_name="resultats_combined.csv", mime="text/csv")
