# analyze_combined.py
import streamlit as st
import pandas as pd
import plotly.express as px
import utils
from sidebar_options import get_sidebar_options
from report_utils import generer_et_afficher_rapport
from verbatim_analyzer.marketing_analyzer import extract_marketing_clusters_with_openai, associer_sous_themes_par_similarity
from streamlit_tree_select import tree_select

def run():
    st.title("üß© Analyse compl√®te des verbatims")
    st.markdown("""
    Bienvenue dans le module **Analyse combin√©e**.  
    Suivez les √©tapes ci-dessous pour explorer vos verbatims selon les approches **Marketing** ou **IA Rating**.
    """)

    # === √âtape 1 : Chargement fichier ===
    st.header("üìÇ √âtape 1 : Import du fichier")
    uploaded_file = st.file_uploader("T√©l√©versez un fichier CSV", type="csv")

    if uploaded_file is None:
        st.info("En attente d‚Äôun fichier CSV‚Ä¶")
        st.stop()

    try:
        df = pd.read_csv(uploaded_file)
        st.success(f"‚úÖ {len(df)} lignes charg√©es")
    except Exception as e:
        st.error(f"Erreur lors de la lecture du fichier : {e}")
        st.stop()

    # Validation colonnes
    if "Verbatim public" not in df.columns:
        st.error("‚ùå Le fichier doit contenir la colonne 'Verbatim public'.")
        st.stop()

    df["Verbatim complet"] = df["Verbatim public"].fillna("") + " " + df.get("Verbatim priv√©", "").fillna("")

    # === √âtape 2 : Choix du mode d‚Äôanalyse ===
    st.header("‚öôÔ∏è √âtape 2 : Choisissez le mode d‚Äôanalyse")
    mode = st.radio(
        "Quelle approche souhaitez-vous utiliser ?",
        ["Analyse Marketing (note client)", "Analyse IA (note g√©n√©r√©e automatiquement)"],
        horizontal=True
    )

    options = get_sidebar_options(uploaded_file)

    # === √âtape 3 : Param√©trage & Extraction des th√®mes ===
    if st.button("üîÑ R√©-extraire les clusters via OpenAI"):
        if "themes_extraits" in st.session_state:
            del st.session_state["themes_extraits"]
        st.rerun()
    
    st.header("üß† √âtape 3 : D√©finition des th√®mes")
    col1, col2 = st.columns(2)

    with col1:
        use_openai = st.toggle("Utiliser OpenAI pour extraire les clusters", options["use_openai"])
    with col2:
        nb_clusters = st.slider("Nombre de clusters (si OpenAI)", 3, 15, options["nb_clusters"])

    themes = []

    # üîÅ Si on a d√©j√† des th√®mes extraits en m√©moire, on les r√©utilise
    if "themes_extraits" in st.session_state:
        themes = st.session_state["themes_extraits"]

    # ‚öôÔ∏è Extraction seulement si OpenAI activ√© ET pas d√©j√† fait
    elif use_openai:
        with st.spinner("Extraction automatique via OpenAI..."):
            try:
                texts_public = df["Verbatim public"].astype(str).tolist()
                texts_private = df["Verbatim priv√©"].astype(str).tolist() if "Verbatim priv√©" in df.columns else [""] * len(df)
                themes = extract_marketing_clusters_with_openai(texts_public, texts_private, nb_clusters)
                st.session_state["themes_extraits"] = themes
                st.success("‚úÖ Clusters extraits automatiquement")
                st.rerun()
            except Exception as e:
                st.error(f"Erreur OpenAI : {e}")
                st.stop()

    else:
        user_themes = st.text_area("Th√®mes manuels (JSON ou CSV)").strip()
        if not user_themes:
            st.warning("‚ö†Ô∏è Fournissez une liste de th√®mes manuelle ou activez OpenAI.")
            st.stop()
        try:
            themes = pd.read_json(user_themes).to_dict(orient="records")
        except Exception:
            themes = [{"theme": t.strip(), "subthemes": []} for t in user_themes.split(",") if t.strip()]
        st.success(f"‚úÖ {len(themes)} th√®mes charg√©s manuellement")


    # --- Modification / Ajout de clusters ---
    st.divider()
    st.markdown("### ‚úèÔ∏è Modification / Ajout de clusters")

    # Ajouter un nouveau th√®me
    with st.expander("‚ûï Ajouter un nouveau th√®me"):
        new_theme = st.text_input("Nom du nouveau th√®me")
        if st.button("Ajouter le th√®me"):
            if new_theme and all(t["theme"] != new_theme for t in themes):
                themes.append({"theme": new_theme, "subthemes": []})
                st.session_state["themes_extraits"] = themes
                st.success(f"Th√®me **{new_theme}** ajout√© ‚úÖ")
                st.rerun()

    # Ajouter un sous-th√®me √† un th√®me existant
    with st.expander("‚ûï Ajouter un sous-th√®me √† un th√®me existant"):
        theme_choice = st.selectbox("S√©lectionnez le th√®me parent", [t["theme"] for t in themes])
        new_sub = st.text_input("Nom du nouveau sous-th√®me")
        new_keywords = st.text_input("Mots-cl√©s associ√©s (s√©par√©s par une virgule)")
        if st.button("Ajouter le sous-th√®me"):
            if new_sub:
                keywords_list = [kw.strip() for kw in new_keywords.split(",") if kw.strip()]
                for t in themes:
                    if t["theme"] == theme_choice:
                        t.setdefault("subthemes", []).append({"label": new_sub, "keywords": keywords_list})
                        break
                st.session_state["themes_extraits"] = themes
                st.success(f"Sous-th√®me **{new_sub}** ajout√© √† **{theme_choice}** ‚úÖ")
                st.rerun()

    # --- Arborescence interactive ---
    st.divider()
    st.markdown("### üå≥ Arborescence des clusters d√©tect√©s / d√©finis")

    def convertir_en_tree_data(themes):
        data = []
        for t in themes:
            children = []
            for s in t.get("subthemes", []):
                label = s.get("label") if isinstance(s, dict) else s
                keywords = s.get("keywords", []) if isinstance(s, dict) else []
                keyword_hint = f" ‚Äî mots-cl√©s: {', '.join(keywords)}" if keywords else ""
                children.append({
                    "label": f"{label}{keyword_hint}",
                    "value": f"{t['theme']}::{label}"
                })
            data.append({
                "label": t.get("theme", "Th√®me sans nom"),
                "value": t.get("theme", "Th√®me sans nom"),
                "children": children
            })
        return data

    tree_data = convertir_en_tree_data(themes)

    selected_nodes = tree_select(
        tree_data,
        "S√©lectionnez les th√®mes et sous-th√®mes √† retenir",
        key="cluster_tree"
    )

    if selected_nodes and selected_nodes.get("checked"):
        st.session_state["selected_clusters"] = selected_nodes["checked"]
        st.success(f"üìÇ Clusters valid√©s : {', '.join(st.session_state['selected_clusters'])}")
    else:
        st.info("üü° Aucun cluster valid√© dans l‚Äôarbre.")

    def filtrer_themes(themes, selection):
        selection_set = set(selection or [])
        filtres = []
        for t in themes:
            theme_name = t.get("theme", "")
            subthemes = []
            for s in t.get("subthemes", []):
                label = s.get("label") if isinstance(s, dict) else s
                value = f"{theme_name}::{label}" if label else theme_name
                if value in selection_set:
                    subthemes.append(s)
            if theme_name in selection_set:
                filtres.append(t)
            elif subthemes:
                filtres.append({"theme": theme_name, "subthemes": subthemes})
        return filtres

    themes_selectionnes = filtrer_themes(themes, st.session_state.get("selected_clusters", []))

    # Aper√ßu du JSON final r√©ellement utilis√©
    with st.expander("üìú JSON final des th√®mes s√©lectionn√©s"):
        if themes_selectionnes:
            st.json(themes_selectionnes)
        else:
            st.info("Aucun cluster s√©lectionn√© pour le moment.")

    # üö¶ Blocage tant que rien n‚Äôest s√©lectionn√©
    if "selected_clusters" not in st.session_state or not st.session_state["selected_clusters"]:
        st.warning("‚ö†Ô∏è Vous devez valider au moins un cluster avant de continuer.")
        st.stop()



    # === √âtape 4 : Calcul des notes ===
    st.header("üí¨ √âtape 4 : Calcul des notes")
    if mode.startswith("Analyse IA"):
        st.info("Les notes sont g√©n√©r√©es automatiquement par IA (1 √† 5)")
        df["Note IA"] = df["Verbatim public"].astype(str).apply(utils.calculer_note_ia)
        note_col = "Note IA"
    else:
        if "Note globale avis 1" not in df.columns:
            st.error("‚ùå Le fichier doit contenir une colonne 'Note globale avis 1'.")
            st.stop()
        note_col = "Note globale avis 1"

    st.success(f"‚úÖ Notes pr√™tes ({note_col})")

    # === √âtape 5 : Association sous-th√®mes ===
    st.write("DEBUG options =", options)

    # Gestion de plusieurs formats possibles de retour
    if isinstance(options, dict):
        model_choice = options.get("model_choice", "MiniLM")
        seuil_similarite = options.get("seuil_similarite", 0.75)
    elif isinstance(options, list):
        # Si c‚Äôest une liste de dictionnaires
        if len(options) > 0 and isinstance(options[0], dict):
            model_choice = options[0].get("model_choice", "MiniLM")
            seuil_similarite = options[0].get("seuil_similarite", 0.75)
        else:
            # Valeurs par d√©faut si c‚Äôest une liste simple
            model_choice, seuil_similarite = "MiniLM", 0.75
    else:
        model_choice, seuil_similarite = "MiniLM", 0.75

    # Choix du mod√®le selon l‚Äôoption
    model_name = "all-MiniLM-L6-v2" if model_choice == "MiniLM" else "bert-base-nli-mean-tokens"

    # Utiliser uniquement les clusters valid√©s pour la suite
    themes_utilises = themes_selectionnes if themes_selectionnes else themes
    st.session_state["themes_valides"] = themes_utilises

    # Association des sous-th√®mes
    df_enriched = associer_sous_themes_par_similarity(
        df,
        themes=themes_utilises,
        text_col="Verbatim complet",
        model_name=model_name,
        seuil_similarite=seuil_similarite
    )
    subtheme_cols = [c for c in df_enriched.columns if "::" in c]
    if not subtheme_cols:
        st.warning("‚ö†Ô∏è Aucun sous-th√®me d√©tect√©.")
        st.stop()

    # === √âtape 6 bis : V√©rification des incoh√©rences ===
    st.header("üß© √âtape 6 bis : V√©rification des incoh√©rences s√©mantiques")

    if st.toggle("Activer la d√©tection des incoh√©rences", value=False):
        with st.spinner("üîç V√©rification des incoh√©rences en cours..."):
            incoherences = utils.verifier_coherence_semantique(
                df_enriched, subtheme_cols, seuil=0.3, alpha=0.7
            )

        if incoherences.empty:
            st.success("‚úÖ Aucune incoh√©rence d√©tect√©e.")
        else:
            st.warning(f"‚ö†Ô∏è {len(incoherences)} incoh√©rences d√©tect√©es.")
            st.dataframe(incoherences)

            # Construction de la matrice finale
            matrice_finale = utils.construire_matrice_finale(df_enriched, incoherences, subtheme_cols)
            st.markdown("### üìê Matrice finale (avec d√©cisions)")
            st.dataframe(matrice_finale)

            # Suppression des incoh√©rences dans df_enriched
            avant = len(df_enriched)
            for _, row in incoherences.iterrows():
                verb = row["Verbatim"]
                sous_theme = row["Sous-th√®me"]
                if row["Decision"] in ["‚ö†Ô∏è Suspect", "Non retenue"]:
                    df_enriched.loc[df_enriched["Verbatim complet"] == verb, sous_theme] = pd.NA
            df_enriched = df_enriched[df_enriched[subtheme_cols].notna().any(axis=1)]
            apres = len(df_enriched)

            st.info(f"üßπ Nettoyage : {avant - apres} verbatims incoh√©rents supprim√©s ({apres} restants).")

            # Export optionnel
            csv_incoh = utils.preparer_csv_export(incoherences, "incoherences_detectees.csv")
            st.download_button(
                "‚¨áÔ∏è T√©l√©charger les incoh√©rences",
                data=csv_incoh,
                file_name="incoherences_detectees.csv",
                mime="text/csv"
            )

        st.success("‚úÖ Nettoyage termin√©, passage √† la visualisation possible.")



    # === √âtape 6 : Visualisations ===
    st.header("üìä √âtape 6 : Visualisation des r√©sultats")
    tabs = st.tabs(["üìà Statistiques", "üí¨ Verbatims", "ü•ß R√©partition", "üßæ Rapport"])

    with tabs[0]:
        st.subheader("Moyenne des notes par sous-th√®me")
        df_melted = df_enriched[[note_col] + subtheme_cols].melt(id_vars=note_col, var_name="Sous-th√®me", value_name="Assoc").dropna()
        stats = df_melted.groupby("Sous-th√®me")[note_col].agg(["count", "mean"]).sort_values("mean", ascending=False)
        st.dataframe(stats)
        fig = px.bar(stats, x=stats.index, y="mean", title="Moyenne des notes par sous-th√®me")
        st.plotly_chart(fig, use_container_width=True)

    with tabs[1]:
        st.subheader("Exemples de verbatims")
        for col in subtheme_cols[:5]:
            subset = df_enriched[df_enriched[col].notna()].head(3)
            st.markdown(f"**{col}**")
            for _, row in subset.iterrows():
                st.markdown(f"- {row['Verbatim public']} ({note_col}: {row[note_col]})")

    with tabs[2]:
        st.subheader("R√©partition des sous-th√®mes")
        counts = df_enriched[subtheme_cols].notna().sum().reset_index()
        counts.columns = ["Sous-th√®me", "Occurrences"]
        fig_pie = px.pie(counts, names="Sous-th√®me", values="Occurrences", title="R√©partition des verbatims par sous-th√®me")
        st.plotly_chart(fig_pie, use_container_width=True)

    with tabs[3]:
        if st.button("üìù G√©n√©rer le rapport complet"):
            generer_et_afficher_rapport(
                stats,
                titre=f"Rapport synth√®se - {mode}",
                filename=f"rapport_{'ia' if 'IA' in mode else 'marketing'}.pdf"
            )

    # === √âtape 7 : Export CSV ===
    st.header("‚¨áÔ∏è √âtape 7 : Export des r√©sultats")
    csv_bytes = utils.preparer_csv_export(df_enriched, f"resultats_{'ia' if 'IA' in mode else 'marketing'}_fusion.csv")
    st.download_button("T√©l√©charger les r√©sultats", data=csv_bytes, file_name="resultats_combined.csv", mime="text/csv")
