import streamlit as st
import pandas as pd
import numpy as np
import json
import logging
import re
import platform
import psutil
import matplotlib.pyplot as plt
import seaborn as sns
from transformers import pipeline
from concurrent.futures import ThreadPoolExecutor
from verbatim_analyzer.database import init_db
from verbatim_analyzer.marketing_analyzer import (
    extract_marketing_clusters_with_openai,
    associer_sous_themes_par_similarity
)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sentence_transformers import SentenceTransformer, util
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

from verbatim_analyzer.report_generator import generer_rapport_openai, exporter_rapport_pdf
from typing import List, Optional
import datetime as dt
import matplotlib.patches as patches
import plotly.express as px
from openai import OpenAI
client = OpenAI()

# Chargement du mod√®le RoBERTa (multilingue)
analyser_sentiment = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

# Liste √©tendue de mots/expressions n√©gatives (ajustable)
REGEX_MOTS_NEGATIFS = re.compile(
    r"\b(manque|nul|horrible|catastrophique|d√©cevant|trop long|attente interminable|mal organis√©|inutile|d√©plorable|pas\s+(terrible|bon|correct|agr√©able)|rien de sp√©cial|tr√®s cher|arnaque)\b",
    flags=re.IGNORECASE
)


def construire_matrice_finale(df_enriched, incoherences, subtheme_cols, note_col="Note globale avis 1"):
    matrice = pd.DataFrame(index=df_enriched.index)

    for col in subtheme_cols:
        for idx in df_enriched.index:
            row = incoherences[(incoherences["Verbatim"] == df_enriched.at[idx, "Verbatim complet"]) &
                               (incoherences["Sous-th√®me"] == col)]
            if not row.empty and row.iloc[0]["Decision"] == "Non retenue":
                matrice.at[idx, col] = np.nan
            else:
                matrice.at[idx, col] = df_enriched.at[idx, note_col] if pd.notna(df_enriched.at[idx, col]) else np.nan

    matrice.insert(0, "Verbatim complet", df_enriched["Verbatim complet"])
    matrice.insert(1, "Note globale", df_enriched[note_col])

    # ‚úÖ Log de suivi
    logging.info(f"üìê Matrice finale construite : {matrice.shape[0]} lignes √ó {matrice.shape[1]} colonnes")

    return matrice

# Mots-cl√©s n√©gatifs ou positifs √† surveiller (ajustable)
MOTS_NEGATIFS = ["manque", "insuffisant", "mauvais", "probl√®me", "attente", "cher", "d√©cevant"]
MOTS_POSITIFS = ["magique", "f√©√©rique", "excellent", "bravo", "super", "parfait"]

def coherence_note_mot(note, sous_theme):
    """Retourne False si la note est incoh√©rente avec le sens du sous-th√®me."""
    st_lower = sous_theme.lower()

    if note >= 5 and any(m in st_lower for m in MOTS_NEGATIFS):
        return False
    if note <= 2 and any(m in st_lower for m in MOTS_POSITIFS):
        return False
    return True





def verifier_coherence_semantique(
    df,
    subtheme_cols,
    seuil=0.3,
    alpha=0.9,              # poids MiniLM (0.9 = 90% MiniLM, 10% TF-IDF)
    model_name="all-MiniLM-L6-v2"
):
    """
    V√©rifie la coh√©rence verbatim ‚Üî sous-th√®me via MiniLM + TF-IDF + logique note/mots.
    Retourne un DataFrame long avec Verbatim, Sous-th√®me, Similarit√© (pond√©r√©e), Coh√©rence.
    - seuil : si score final < seuil ‚Üí "‚ö†Ô∏è Suspect"
    - alpha : pond√©ration MiniLM (0.9 MiniLM + 0.1 TF-IDF par d√©faut)
    - √©limination directe si note contradictoire avec polarit√© implicite du sous-th√®me
    """

    # üîπ Listes de mots pour d√©tecter le ton des sous-th√®mes
    MOTS_NEGATIFS = ["manque", "insuffisant", "mauvais", "probl√®me", "attente", "cher", "d√©cevant", "rat√©"]
    MOTS_POSITIFS = ["magique", "f√©√©rique", "excellent", "bravo", "super", "parfait"]

    def coherence_note_mot(note, sous_theme: str) -> bool:
        """Retourne False si la note est incoh√©rente avec le sous-th√®me."""
        st_lower = sous_theme.lower()
        if note >= 5 and any(m in st_lower for m in MOTS_NEGATIFS):
            return False
        if note <= 2 and any(m in st_lower for m in MOTS_POSITIFS):
            return False
        return True

    # --- Collecte verbatims ‚Üî sous-th√®mes ---
    rows = []
    for col in subtheme_cols:
        mask = df[col].notna()
        for idx in df[mask].index:
            rows.append({
                "Verbatim": str(df.at[idx, "Verbatim complet"]),
                "Sous-th√®me": col,
                "Note globale": df.at[idx, "Note globale avis 1"]
            })

    assignments = pd.DataFrame(rows)
    if assignments.empty:
        return pd.DataFrame()

    verbatims = assignments["Verbatim"].tolist()
    subthemes = assignments["Sous-th√®me"].tolist()

    # --- TF-IDF ---
    if USE_TFIDF:
        texts = verbatims + subthemes
        tfidf = TfidfVectorizer()
        X = tfidf.fit_transform(texts)
        verbatim_vecs = X[:len(verbatims)]
        subtheme_vecs = X[len(verbatims):]
        sims_tfidf = [cosine_similarity(verbatim_vecs[i], subtheme_vecs[i])[0][0]
                      for i in range(len(verbatims))]
    else:
        sims_tfidf = [0.0] * len(verbatims)

    # --- MiniLM ---
    model = SentenceTransformer(model_name)
    emb_verbatims = model.encode(verbatims, convert_to_tensor=True)
    emb_subthemes = model.encode(subthemes, convert_to_tensor=True)
    sims_minilm = util.cos_sim(emb_verbatims, emb_subthemes).diagonal().cpu().numpy().tolist()

    # --- Fusion pond√©r√©e ---
    sims_final = [alpha * s_minilm + (1 - alpha) * s_tfidf
                  for s_minilm, s_tfidf in zip(sims_minilm, sims_tfidf)]

    # --- Ajout des scores ---
    assignments["Similarit√©_TFIDF"] = sims_tfidf
    assignments["Similarit√©_MiniLM"] = sims_minilm
    assignments["Score_final"] = sims_final

    # --- Coh√©rence finale ---
    decisions = []
    for i, row in assignments.iterrows():
        note = row["Note globale"]
        sous_theme = row["Sous-th√®me"]
        s_tfidf = row["Similarit√©_TFIDF"]
        score = row["Score_final"]

        # 1Ô∏è‚É£ R√®gle lexicale stricte TF-IDF
        if s_tfidf < 0.03:
            decisions.append("Non retenue")
            continue

        # 2Ô∏è‚É£ R√®gle "note ‚Üî mot du sous-th√®me"
        if not coherence_note_mot(note, sous_theme):
            decisions.append("Non retenue")
            continue

        # 3Ô∏è‚É£ R√®gle de similarit√©
        if score < seuil:
            decisions.append("‚ö†Ô∏è Suspect")
        else:
            decisions.append("OK")

    assignments["Coh√©rence"] = decisions
    assignments["Decision"] = decisions  # alias pour compatibilit√©

    return assignments



def tracer_bulles_corr_accel_plotly(stats: pd.DataFrame, top_labels: int = 15, inclure_extremes: bool = True):
    if stats.empty:
        st.warning("Aucune donn√©e pour tracer le graphe.")
        return

    data = stats.reset_index().rename(columns={"Sous-th√®me":"Sous-theme"})
    data["Cat√©gorie"] = np.where(data["is_recent_first"], "Premi√®res occurrences r√©centes", "Occurrences √©tablies")

    # S√©lection des labels (moins de bruit)
    to_label = set(data.nlargest(top_labels, "prop")["Sous-theme"])
    if inclure_extremes:
        to_label |= set(data.nsmallest(5, "corr")["Sous-theme"])
        to_label |= set(data.nlargest(5, "corr")["Sous-theme"])
        to_label |= set(data.nsmallest(5, "accel")["Sous-theme"])
        to_label |= set(data.nlargest(5, "accel")["Sous-theme"])
    data["label"] = np.where(data["Sous-theme"].isin(to_label), data["Sous-theme"], "")

    fig = px.scatter(
        data,
        x="corr", y="accel",
        size="prop", size_max=48,
        color="Cat√©gorie",
        color_discrete_map={
            "Premi√®res occurrences r√©centes": "#ffb74d",
            "Occurrences √©tablies": "#f2f2f2",
        },
        hover_name="Sous-theme",
        hover_data={
            "corr":":.2f", "accel":":.2f",
            "prop":":.1%", "first_seen": True,
            "Sous-theme": False  # d√©j√† dans hover_name
        }
    )

    # Quadrillage / zones color√©es comme ta maquette
    fig.add_hline(y=0, line_color="black", line_width=1)
    fig.add_vline(x=0, line_color="black", line_width=1)
    fig.add_shape(type="rect", x0=-1, x1=0, y0=-1e9, y1=1e9, fillcolor="#f8d7da", opacity=0.25, line_width=0)
    fig.add_shape(type="rect", x0=0, x1=1, y0=-1e9, y1=1e9, fillcolor="#d4edda", opacity=0.25, line_width=0)

    # Petites √©tiquettes uniquement pour la s√©lection "to_label"
    #for _, r in data[data["label"]!=""].iterrows():
    #    fig.add_annotation(x=r["corr"], y=r["accel"], text=r["label"],
    #                       showarrow=False, xanchor="left", yanchor="bottom", xshift=6, yshift=6, font={"size":10})

    fig.update_layout(
        title="Corr√©lation √ó Acc√©l√©ration des sous‚Äëth√®mes (taille = % d‚Äôoccurrences)",
        xaxis_title="Corr√©lation avec la note (‚àí ‚Ä¶ +)",
        yaxis_title="Acc√©l√©ration des occurrences (pente normalis√©e)",
        legend_title="",
        margin=dict(l=10, r=10, t=40, b=10),
    )
    # bornes X lisibles
    fig.update_xaxes(range=[-1, 1], zeroline=False)
    st.plotly_chart(fig, use_container_width=True)

def construire_matrice_verbatims(df_enriched, subtheme_cols, note_col="Note globale avis 1"):
    """
    Construit une matrice verbatim √ó sous-th√®mes :
    - Lignes = verbatims
    - Colonnes = sous-th√®mes
    - Valeur = note du verbatim si rattach√©, NaN sinon
    """
    matrice = pd.DataFrame(index=df_enriched.index)

    for col in subtheme_cols:
        # Si le verbatim est rattach√© (col non NaN), on met la note
        matrice[col] = np.where(df_enriched[col].notna(), df_enriched[note_col], np.nan)

    # On peut rajouter les colonnes de contexte utiles
    matrice.insert(0, "Verbatim complet", df_enriched["Verbatim complet"])
    matrice.insert(1, "Note globale", df_enriched[note_col])

    return matrice

def _occ_time_series(df, col_date, present_mask, freq="W"):
    ts = (
        df.loc[present_mask, [col_date]]
        .dropna()
        .assign(n=1)
        .set_index(col_date)
        .resample(freq)["n"].sum()
        .fillna(0.0)
    )
    return ts

def verifier_polarite_openai(sous_theme: str, polarite_estimee: str, note_moyenne: float) -> str:
    """
    V√©rifie ou corrige la polarit√© avec OpenAI.
    Retourne "Positive", "Negative" ou "Neutre".
    """
    prompt = f"""
    Voici un sous-th√®me client : "{sous_theme}"
    Polarit√© d√©tect√©e automatiquement : {polarite_estimee}
    Note moyenne associ√©e : {note_moyenne}

    Corrige la polarit√© en tenant compte du sens r√©el du sous-th√®me.
    R√©ponds uniquement par un mot : Positive, Negative ou Neutre.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0
        )
        correction = response.choices[0].message.content.strip()
        if correction.lower().startswith("pos"):
            return "Positive"
        elif correction.lower().startswith("neg"):
            return "Negative"
        else:
            return "Neutre"
    except Exception as e:
        logging.warning(f"‚ö†Ô∏è OpenAI indisponible ({e}) ‚Üí on garde {polarite_estimee}")
        return polarite_estimee


def calculer_bulles_corr_accel(
    df_enriched: pd.DataFrame,
    subtheme_cols: List[str],
    note_col: str = "Note globale avis 1",
    date_col: Optional[str] = "Date avis",
    freq: str = "W",                   # "W", "M", "D"
    recent_k_periods: int = 3          # alerte orange si 1√®re occurrence dans les K derni√®res p√©riodes
) -> pd.DataFrame:
    """
    Retourne un DF index√© par Sous-th√®me avec:
      - corr : corr√©lation (pr√©sence vs note)
      - accel : pente normalis√©e des occurrences (acc√©l√©ration)
      - prop : part des occurrences (taille bulle)
      - first_seen : 1√®re date d'occurrence
      - is_recent_first : bool alerte "premi√®res occurrences r√©centes"
    """
    df = df_enriched.copy()
    y = pd.to_numeric(df[note_col], errors="coerce")

    # Taille = % d'occurrences (tous sous-th√®mes confondus)
    total_occ = df[subtheme_cols].notna().sum().sum()
    prop = {c: (df[c].notna().sum() / total_occ) if total_occ else 0.0 for c in subtheme_cols}

    # Corr√©lation point-bis√©rielle approx (corr Pearson entre 0/1 et note)
    corr = {}
    for c in subtheme_cols:
        x = df[c].notna().astype(float)
        m = x.notna() & y.notna()
        if m.sum() >= 3 and x[m].std() > 0 and y[m].std() > 0:
            corr[c] = float(np.corrcoef(x[m], y[m])[0, 1])
        else:
            corr[c] = 0.0

    # Acc√©l√©ration & premi√®re occurrence
    accel, first_seen, recent_first = {}, {}, {}
    if date_col in df.columns:
        df[date_col] = pd.to_datetime(df[date_col], errors="coerce")
        # borne haute pour savoir si "r√©cent"
        now = (df[date_col].max() or pd.Timestamp.utcnow())
        # taille p√©riode pour remonter K p√©riodes
        if freq == "W":
            recent_threshold = now - pd.Timedelta(weeks=recent_k_periods)
        elif freq == "M":
            recent_threshold = now - pd.DateOffset(months=recent_k_periods)
        else:
            recent_threshold = now - pd.Timedelta(days=recent_k_periods)

        for c in subtheme_cols:
            mask = df[c].notna()
            dmin = df.loc[mask, date_col].min()
            first_seen[c] = dmin
            recent_first[c] = bool(pd.notna(dmin) and dmin >= recent_threshold)

            ts = _occ_time_series(df, date_col, mask, freq=freq)
            if len(ts) < 3:
                accel[c] = 0.0
                continue
            x_idx = np.arange(len(ts))
            slope = np.polyfit(x_idx, ts.values, 1)[0]
            std = ts.std()
            accel[c] = float(slope / (std if std > 0 else 1.0))
    else:
        for c in subtheme_cols:
            accel[c] = 0.0
            first_seen[c] = pd.NaT
            recent_first[c] = False

    out = pd.DataFrame({
        "Sous-th√®me": subtheme_cols,
        "corr": [corr[c] for c in subtheme_cols],
        "accel": [accel[c] for c in subtheme_cols],
        "prop": [prop[c] for c in subtheme_cols],
        "first_seen": [first_seen[c] for c in subtheme_cols],
        "is_recent_first": [recent_first[c] for c in subtheme_cols],
    }).set_index("Sous-th√®me")

    return out.sort_values("prop", ascending=False)

def tracer_bulles_corr_accel(
    stats: pd.DataFrame,
    title: str = "Corr√©lation √ó Acc√©l√©ration des sous‚Äëth√®mes",
    top_labels: int = 20
):
    if stats.empty:
        st.warning("Aucune donn√©e pour tracer le graphe.")
        return

    fig, ax = plt.subplots(figsize=(12, 7))

    # Fond en bandes (rouge √† gauche, vert √† droite) fa√ßon maquette
    ax.add_patch(patches.Rectangle((-1.0, ax.get_ylim()[0]), 1.0, 9999, color="#f8d7da", alpha=0.35))
    ax.add_patch(patches.Rectangle((0.0, ax.get_ylim()[0]), 1.0, 9999, color="#d4edda", alpha=0.35))

    # axes 0 (corr√©lation=0, acc√©l√©ration=0)
    ax.axvline(0, color="black", linewidth=1)
    ax.axhline(0, color="black", linewidth=1)

    # Taille des bulles
    sizes = (stats["prop"] * 7000).clip(lower=60)

    # Couleur: orange si "r√©cent", sinon gris avec bord violet
    face_colors = np.where(stats["is_recent_first"], "#ffb74d", "#f2f2f2")
    edge_colors = "#7C2A90"

    sc = ax.scatter(
        stats["corr"], stats["accel"], s=sizes,
        c=face_colors, edgecolors=edge_colors, linewidths=2, alpha=0.95
    )

    # Labels pour top bulles
    for name in stats.head(top_labels).index:
        ax.annotate(name, (stats.loc[name, "corr"], stats.loc[name, "accel"]),
                    xytext=(6, 6), textcoords="offset points", fontsize=9)

    ax.set_xlim(-1.0, 1.0)
    # y auto; mais garde un minimum lisible
    ymin, ymax = stats["accel"].min(), stats["accel"].max()
    pad = max((ymax - ymin) * 0.15, 0.3)
    ax.set_ylim(ymin - pad, ymax + pad)

    ax.set_xlabel("Corr√©lation avec la note (‚àí ‚Ä¶ +)")
    ax.set_ylabel("Acc√©l√©ration des occurrences (pente normalis√©e)")
    ax.set_title(title)

    # L√©gendes custom
    leg1 = patches.Patch(facecolor="#ffb74d", edgecolor=edge_colors, label="Premi√®res occurrences r√©centes")
    leg2 = patches.Patch(facecolor="#f2f2f2", edgecolor=edge_colors, label="Occurrences √©tablies")
    ax.legend(handles=[leg1, leg2], loc="upper left", frameon=False)

    st.pyplot(fig)



def contient_mots_negatifs(texte):
    return any(mot in texte.lower() for mot in mots_negatifs)

def analyser_sentiment_mixte(texte):
    try:
        texte = texte.strip()
        if not texte:
            return {"label": "Neutral", "score": 0.0, "source": "vide"}

        # Analyse IA RoBERTa
        res = analyser_sentiment(texte[:512])[0]
        score_label = res['label']
        score = int(score_label.split()[0])

        # Heuristique de mots n√©gatifs
        negatif_detecte = contient_mots_negatifs(texte)

        # Heuristique d'ajustement
        if score >= 4 and negatif_detecte:
            # Avis globalement positif mais √©l√©ments critiques ‚Üí neutre
            return {"label": "Mixed (positif mais critique)", "score": score, "source": "mixte"}
        elif score <= 2 and not negatif_detecte:
            # Score bas mais aucune critique explicite ‚Üí douteux
            return {"label": "Mixed (note faible mais pas critique)", "score": score, "source": "mixte"}
        elif negatif_detecte and score >= 3:
            return {"label": "Negative", "score": score, "source": "regex n√©gatif"}
        else:
            return {"label": "Positive" if score >= 4 else "Negative" if score <= 2 else "Neutral", "score": score, "source": "RoBERTa"}

    except Exception as e:
        return {"label": "Erreur", "score": 0, "source": str(e)}


logging.basicConfig(level=logging.INFO)

ASSISTANT_MODEL_NAME = "gpt-4-turbo"

st.set_page_config(layout="wide")
st.title("üß† Analyse des verbatims client")

init_db()

menu = st.sidebar.selectbox("Navigation", ["Marketing"])


# üîç Liste de mots ou expressions indiquant un ressenti potentiellement n√©gatif
mots_negatifs = [
    "souhait", "longue", "absence", "manque", "trop long", "dommage", "pas assez", "trop cher", "impossible",
    "file d‚Äôattente", "interminable", "aucune", "d√©cevant", "catastrophique",
    "rien pour", "manquait", "ne fonctionne pas", "sans int√©r√™t", "n'a pas aim√©",
    "d√©ception", "pas bon", "pas top", "nul", "ennuyeux", "rat√©", "erreur", "√† √©viter"
]
USE_TFIDF = True   # ou False si on veut d√©sactiver
TFIDF_ALPHA = 0.3  # poids de TF-IDF dans la pond√©ration


def evaluer_veracite_polarite(row, seuil_bas=3, seuil_haut=4):
    polarite = row["Polarit√© estim√©e"]
    note = row["mean"]

    if polarite == "Positive" and note <= seuil_bas:
        return "‚ùå Faux positif"
    elif polarite == "Negative" and note >= seuil_haut:
        return "‚ùå Faux n√©gatif"
    elif polarite == "Positive" and note >= seuil_haut:
        return "‚úÖ Vrai positif"
    elif polarite == "Negative" and note <= seuil_bas:
        return "‚úÖ Vrai n√©gatif"
    else:
        return "üü° Ambigu / mixte"



def afficher_dataframe_propre(df: pd.DataFrame, cmap: str = "Blues"):
    """
    Affiche une dataframe stylis√©e en supprimant les lignes/colonnes enti√®rement vides
    et indique combien ont √©t√© ignor√©es. R√©initialise l'index si n√©cessaire pour √©viter les erreurs de style.
    """
    if df.empty:
        st.warning("üì≠ La table est vide, rien √† afficher.")
        return

    # Sauvegarde des tailles avant nettoyage
    lignes_avant = df.shape[0]
    colonnes_avant = df.shape[1]

    # Nettoyage : suppression des lignes/colonnes compl√®tement vides
    df_cleaned = df.dropna(how="all", axis=0).dropna(how="all", axis=1)

    lignes_apres = df_cleaned.shape[0]
    colonnes_apres = df_cleaned.shape[1]

    lignes_supprimees = lignes_avant - lignes_apres
    colonnes_supprimees = colonnes_avant - colonnes_apres

    if lignes_supprimees > 0 or colonnes_supprimees > 0:
        st.info(f"üîç {lignes_supprimees} ligne(s) et {colonnes_supprimees} colonne(s) vides ont √©t√© ignor√©es.")

    if df_cleaned.empty:
        st.warning("üö´ Tous les √©l√©ments ont √©t√© filtr√©s (table vide apr√®s nettoyage).")
        return

    # ‚úÖ S√©curit√© : r√©initialise index si non unique (n√©cessaire pour .style)
    if not df_cleaned.index.is_unique:
        df_cleaned = df_cleaned.reset_index()

    if not df_cleaned.columns.is_unique:
        df_cleaned.columns = [f"{col}_{i}" if list(df_cleaned.columns).count(col) > 1 else col
                              for i, col in enumerate(df_cleaned.columns)]

    st.dataframe(df_cleaned.style.background_gradient(cmap=cmap))



def analyser_par_batches(df, batch_size=1000, process_func=None):
    if process_func is None:
        raise ValueError("Vous devez fournir une fonction process_func(batch_df)")

    total = len(df)
    results = []
    for i in range(0, total, batch_size):
        st.info(f"üß™ Traitement du batch {i//batch_size + 1} / {total//batch_size + 1}")
        batch_df = df.iloc[i:i+batch_size].copy()
        try:
            result = process_func(batch_df)
            if not result.empty:
                results.append(result)
        except Exception as e:
            st.error(f"‚ùå Erreur dans le batch {i//batch_size + 1} : {e}")

    if results:
        return pd.concat(results, ignore_index=True)
    else:
        return pd.DataFrame(columns=["Sous-th√®me", "Polarit√© estim√©e", "V√©racit√© polarit√©"])


def traiter_batch_polarite(batch_df):
    subtheme_cols = [col for col in batch_df.columns if "::" in col]

    if not subtheme_cols:
        return pd.DataFrame(columns=["Sous-th√®me", "Polarit√© estim√©e", "V√©racit√© polarit√©"])

    # Pr√©paration donn√©es fondues
    df_melted_batch = batch_df[["Note globale avis 1"] + subtheme_cols].melt(
        id_vars="Note globale avis 1",
        var_name="Sous-th√®me",
        value_name="Score"
    ).dropna()

    return enrichir_polarite_veracite(df_melted_batch, batch_df, subtheme_cols)




def enrichir_polarite_veracite(df_melted, df_enriched, subtheme_cols):
    polarite_info = []
    total = len(subtheme_cols)
    progress_bar = st.progress(0, text="üìä Analyse de polarit√© des sous-th√®mes...")

    for i, subtheme in enumerate(subtheme_cols):
        textes = df_enriched[df_enriched[subtheme].notna()]["Verbatim complet"].astype(str)
        if textes.empty:
            continue

        with ThreadPoolExecutor(max_workers=8) as executor:
            result_dicts = list(executor.map(analyser_sentiment_mixte, textes))

        labels = [res["label"] if isinstance(res, dict) and "label" in res else "Neutre" for res in result_dicts]
        moyenne = df_melted[df_melted["Sous-th√®me"] == subtheme]["Score"].mean()

        try:
            sentiment_label = pd.Series(labels).mode()[0]
        except IndexError:
            sentiment_label = "Neutre"

        polarite = (
            "Positive" if "pos" in sentiment_label.lower()
            else "Negative" if "neg" in sentiment_label.lower()
            else "Neutre"
        )

        # Correction heuristique locale
        if contient_mots_negatifs(subtheme) and polarite == "Positive":
            polarite = "Neutre"

        # ‚úÖ Rectification finale via OpenAI
        polarite = verifier_polarite_openai(subtheme, polarite, moyenne)


        veracite = evaluer_veracite_polarite({
            "Polarit√© estim√©e": polarite,
            "mean": moyenne
        })

        polarite_info.append({
            "Sous-th√®me": subtheme,
            "Polarit√© estim√©e": polarite,
            "V√©racit√© polarit√©": veracite
        })

        progress_bar.progress((i + 1) / total, text=f"üìä Polarit√© : {subtheme}")

    progress_bar.empty()
    return pd.DataFrame(polarite_info)




def preparer_csv_export(df, filename, label="‚¨áÔ∏è T√©l√©charger CSV"):
    try:
        csv_data = df.to_csv(index=False).encode("utf-8")
        size_kb = len(csv_data) / 1024
        logging.info(f"üóÇÔ∏è Export CSV ‚Äî {filename} ‚Äî taille : {size_kb:.1f} KB")
        st.download_button(label=label, data=csv_data, file_name=filename, mime="text/csv")
    except Exception as e:
        logging.exception("‚ùå Erreur pendant l'export CSV")
        st.error(f"Erreur export : {e}")


    

if menu == "Marketing":

    st.info("üìç √âtape 1 : D√©but pipeline Marketing")


    mem = psutil.virtual_memory()
    st.code(f"""
    üìä SYSTEM INFO :
    Python: {platform.python_version()}
    OS: {platform.system()}
    RAM utilis√©e: {mem.used // (1024 ** 2)}MB / {mem.total // (1024 ** 2)}MB
    """)



    st.header("\U0001F4CA Analyse marketing des sous-clusters et notes globales")

    uploaded_file = st.file_uploader("\U0001F4C1 T√©l√©verser un fichier CSV avec notes globales", type="csv")

    # === OPTIONS AFFICHAGE (Marketing) ===
    st.sidebar.markdown("### ‚öôÔ∏è Options d'affichage")

    is_big_file = uploaded_file and uploaded_file.size > 4_000_000

    show_note_comparison = st.sidebar.checkbox("Afficher comparaison des verbatims utilis√©s", value=not is_big_file)
    show_subtheme_table = st.sidebar.checkbox("Afficher tableau sous-th√®mes filtr√©s", value=True)
    show_best_worst = st.sidebar.checkbox("Afficher meilleurs/pires sous-th√®mes", value=not is_big_file)
    show_distribution_chart = st.sidebar.checkbox("Afficher histogramme des scores", value=not is_big_file)
    show_verbatims_examples = st.sidebar.checkbox("Afficher verbatims repr√©sentatifs", value=False)
    show_profil_matrix = st.sidebar.checkbox("Afficher matrice Profil √ó Sous-th√®mes", value=not is_big_file)
    show_matrice_verbatims = st.sidebar.checkbox("Afficher matrice Verbatims √ó Sous-clusters", value=False)
    show_unassigned = st.sidebar.checkbox("Afficher les verbatims non associ√©s", value=False)
    # Option sidebar pour afficher les incoh√©rences
    show_incoherences = st.sidebar.checkbox("Afficher incoh√©rences s√©mantiques", value=False)

    use_openai = st.sidebar.checkbox("Utiliser OpenAI pour les clusters")
    nb_clusters = st.sidebar.slider("Nombre de clusters", min_value=2, max_value=1000, value=5)
    model_choice = st.sidebar.radio("Mod√®le d'encodage", ["MiniLM", "BERT"])
    # Choix du seuil de similarit√© (avec valeur par d√©faut 0.45)
    seuil_similarite = st.sidebar.slider(
        "Seuil de similarit√© (MiniLM/BERT)",
        min_value=0.0,
        max_value=1.0,
        value=0.45,
        step=0.05
    )

    user_themes = ""
    themes = []

    if not use_openai:
        user_themes = st.sidebar.text_area("Liste manuelle des clusters (format JSON accept√© ou simple CSV)")
        
        if not user_themes.strip():
            st.warning("‚ö†Ô∏è Saisissez des th√®mes manuels ou activez l'option OpenAI.")
            st.stop()
        
        try:
            # Tentative de chargement en JSON
            parsed = json.loads(user_themes)
            
            if isinstance(parsed, list) and all(isinstance(t, dict) and "theme" in t and "subthemes" in t for t in parsed):
                themes = parsed
                st.success(f"‚úÖ {len(themes)} th√®me(s) JSON correctement interpr√©t√©(s)")
                with st.expander("üìö Aper√ßu des th√®mes interpr√©t√©s"):
                    for theme in themes:
                        st.markdown(f"### üü¶ {theme['theme']}")
                        for sub in theme['subthemes']:
                            st.markdown(f"- {sub}")

            else:
                raise ValueError("‚ùå Format JSON invalide : chaque √©l√©ment doit avoir 'theme' et 'subthemes'")
        
        except Exception as e:
            # Si JSON √©choue, fallback simple CSV
            themes = [{"theme": t.strip(), "subthemes": []} for t in user_themes.split(",") if t.strip()]
            st.info("‚ÑπÔ∏è Format simple d√©tect√© (pas JSON valide) : seuls les noms de th√®mes seront utilis√©s")

    if uploaded_file is not None:
        try:
            st.info("üìç √âtape 2 : Chargement du CSV")
            df = pd.read_csv(uploaded_file)
            nb_lignes = df.shape[0]
            st.success(f"‚úÖ Fichier charg√© : {nb_lignes} lignes")

            # ‚ûï Estimation de dur√©e
            estimation_minutes = round(nb_lignes * 0.008)  # ‚âà 0.5 sec/ligne
            if estimation_minutes > 1:
                st.warning(f"‚è≥ Le traitement peut prendre environ **{estimation_minutes} minute(s)** selon la charge.")

        except Exception as e:
            st.error(f"Erreur de lecture : {e}")
            st.stop()

        required_cols = ["Verbatim public", "Note globale avis 1"]
        if not all(c in df.columns for c in required_cols):
            st.error("‚ùå Le fichier doit contenir au moins 'Verbatim public' et 'Note globale avis 1'.")
            st.stop()

        texts_public = df["Verbatim public"].astype(str).fillna("").tolist()
        texts_private = df["Verbatim priv√©"].astype(str).fillna("").tolist() if "Verbatim priv√©" in df.columns else [""] * len(texts_public)

        if use_openai:
            with st.spinner("\U0001F52E Extraction des clusters avec OpenAI..."):
                try:
                    themes = extract_marketing_clusters_with_openai(texts_public, texts_private, nb_clusters)
                    st.success("‚úÖ Clusters extraits avec succ√®s")
                    st.markdown("### \U0001F9E0 Th√®mes extraits")
                    for t in themes:
                        st.markdown(f"**üü¶ {t['theme']}**")
                        for s in t['subthemes']:
                            if isinstance(s, dict):
                                st.markdown(f"- {s['label']}  _(mots-cl√©s: {', '.join(s.get('keywords', []))})_")
                            else:
                                st.markdown(f"- {s}")  # fallback pour compat r√©tro

                except Exception as e:
                    st.error(f"Erreur OpenAI : {e}")
                    st.stop()


        df_enriched = df.copy()
        df_enriched["Verbatim complet"] = df["Verbatim public"].fillna("") + " " + df.get("Verbatim priv√©", "").fillna("")

        try:
            model_name = "all-MiniLM-L6-v2" if model_choice == "MiniLM" else "bert-base-nli-mean-tokens"
            logging.info(f"üß† Mod√®le s√©lectionn√© : {model_name}")

            logging.info(f"üß™ Validation themes ‚Äî Nombre total : {len(themes)}")
            for t in themes:
                logging.info(f"üìÇ Th√®me : {t['theme']} ‚Äî {len(t['subthemes'])} sous-th√®mes")

            assert isinstance(themes, list)
            assert all("subthemes" in t for t in themes)
            assert any(t["subthemes"] for t in themes), "‚ùå Aucun sous-th√®me trouv√© dans 'themes'"

            with st.spinner("üîÑ Analyse marketing en cours, cela peut prendre plusieurs minutes..."):
                df_enriched = associer_sous_themes_par_similarity(
                    df_enriched,
                    themes=themes,
                    text_col="Verbatim complet",
                    model_name=model_name,
                    seuil_similarite=seuil_similarite
                )
            logging.info("‚úÖ Attribution des sous-th√®mes r√©ussie")
        except Exception as e:
            logging.exception("‚ùå Erreur lors de l'attribution des sous-th√®mes")
            st.error(f"Erreur lors de l'attribution des sous-th√®mes : {e}")
            st.stop()

        subtheme_cols = [col for col in df_enriched.columns if "::" in col]
        if not subtheme_cols:
            st.error("‚ùå Aucune colonne de sous-th√®me trouv√©e.")
            st.stop()

        # üìê Matrice
        if show_matrice_verbatims:
            matrice = construire_matrice_verbatims(df_enriched, subtheme_cols)
            st.markdown("### üìê Matrice Verbatims √ó Clusters / Sous-clusters")
            st.dataframe(matrice)
            preparer_csv_export(matrice, "matrice_verbatims_clusters.csv", "‚¨áÔ∏è T√©l√©charger la matrice compl√®te")

        # üîç V√©rification de coh√©rence
        if show_incoherences:
            incoherences = verifier_coherence_semantique(
                df_enriched, subtheme_cols, seuil=0.3, alpha=0.7
            )

            if "Decision" not in incoherences.columns:
                logging.warning("‚ö†Ô∏è Pas de colonne Decision dans incoherences")
                incoherences["Decision"] = "OK"

            st.markdown("### üîç V√©rification de coh√©rence verbatim ‚Üî sous-th√®me")
            st.dataframe(incoherences)

            # ‚úÖ Export interm√©diaire
            preparer_csv_export(incoherences, "incoherences.csv", "‚¨áÔ∏è T√©l√©charger incoh√©rences d√©tect√©es")



            # Matrice enrichie avec d√©cision finale
            matrice_finale = construire_matrice_finale(df_enriched, incoherences, subtheme_cols)
            matrice_finale["D√©cision finale"] = np.where(
                matrice_finale[subtheme_cols].notna().any(axis=1),
                "Retenue",
                "Non retenue"
            )

            # Compte clair : uniquement les vrais non retenus
            nb_non_retenus = (matrice_finale["D√©cision finale"] == "Non retenue").sum()
            nb_retenus = (matrice_finale["D√©cision finale"] == "Retenue").sum()

            st.info(f"üìä R√©sultat : {nb_non_retenus} verbatim(s) non retenus ‚Äî {nb_retenus} retenus")

            st.markdown("### üìê Matrice Verbatims √ó Sous-th√®mes (avec d√©cision finale)")
            st.dataframe(matrice_finale)

            preparer_csv_export(matrice_finale, "matrice_verbatims_finale.csv",
                                "‚¨áÔ∏è T√©l√©charger matrice finale")

            # üßπ Suppression des incoh√©rents
            suspects = incoherences[incoherences["Coh√©rence"] == "‚ö†Ô∏è Suspect"]["Verbatim"].unique()
            # üßπ Suppression des incoh√©rents et non retenus
            avant = len(df_enriched)
            for _, row in incoherences.iterrows():
                verb = row["Verbatim"]
                sous_theme = row["Sous-th√®me"]
                if row["Decision"] in ["‚ö†Ô∏è Suspect", "Non retenue"]:
                    df_enriched.loc[df_enriched["Verbatim complet"] == verb, sous_theme] = np.nan

            # Supprimer seulement les verbatims sans aucune association restante
            df_enriched = df_enriched[df_enriched[subtheme_cols].notna().any(axis=1)].copy()
            apres = len(df_enriched)

            #st.info(f"üßπ {avant - apres} verbatim(s) enti√®rement non associ√©s supprim√©s. Restant : {apres}")

        # üìä Stats de base
        df_melted = df_enriched[["Note globale avis 1"] + subtheme_cols].melt(
            id_vars="Note globale avis 1",
            var_name="Sous-th√®me",
            value_name="Score"
        ).dropna()

        subtheme_stats = df_melted.groupby("Sous-th√®me")["Score"].agg(["count", "mean"]).sort_values("mean", ascending=False)

        # üß† Polarit√© + v√©racit√©
        df_polarite = analyser_par_batches(df_enriched, batch_size=1000, process_func=traiter_batch_polarite)

        if df_polarite.empty or "Sous-th√®me" not in df_polarite.columns:
            st.error("‚ùå La polarit√© n‚Äôa pas pu √™tre calcul√©e (table vide).")
            st.stop()

        # üîó Fusion
        merged_stats = subtheme_stats.merge(df_polarite, left_index=True, right_on="Sous-th√®me")
        merged_stats = merged_stats.set_index("Sous-th√®me")

        # Nombre total de verbatims par note
        # √âtape 2 ‚Äì Comparaison entre total, utilis√©s (brut) et verbatims uniques exploit√©s
        note_distribution = df["Note globale avis 1"].value_counts().sort_index()
        used_notes = df_melted["Note globale avis 1"].value_counts().sort_index()

        # Verbatims uniques qui ont √©t√© associ√©s √† au moins un sous-th√®me
        used_unique_notes = (
            df_enriched.loc[df_enriched[subtheme_cols].notna().any(axis=1), "Note globale avis 1"]
            .value_counts()
            .sort_index()
        )

        note_comparison = pd.DataFrame({
            "Total verbatims": note_distribution,
            "Utilis√©s dans l‚Äôanalyse (associations)": used_notes,
            "Verbatims uniques utilis√©s": used_unique_notes
        }).fillna(0).astype(int)

        if show_note_comparison:
            st.markdown("### üßæ Comparaison : verbatims disponibles vs. utilis√©s dans l‚Äôanalyse")
            st.dataframe(note_comparison.style.background_gradient(cmap="Blues"))

            # V√©rification des verbatims non associ√©s √† un sous-th√®me
            nb_unassigned = df_enriched[subtheme_cols].isna().all(axis=1).sum()
            verbatims_non_assignes = df_enriched[df_enriched[subtheme_cols].isna().all(axis=1)]
            st.warning(f"‚ö†Ô∏è {nb_unassigned} verbatim(s) n'ont √©t√© associ√©s √† aucun sous-th√®me.")

            if show_unassigned:
                st.markdown("### üì≠ Verbatims non associ√©s √† un cluster/sous-cluster")
                st.write(f"Nombre total : {len(verbatims_non_assignes)}")
                st.dataframe(verbatims_non_assignes[["Verbatim public", "Note globale avis 1"]])
                
                # ‚úÖ Option d‚Äôexport CSV
                preparer_csv_export(
                    verbatims_non_assignes[["Verbatim public", "Note globale avis 1"]],
                    "verbatims_non_assignes.csv",
                    label="‚¨áÔ∏è T√©l√©charger les verbatims non associ√©s"
                )


        st.write("üßæ Aper√ßu des donn√©es analys√©es (df_melted)", df_melted.head(20))
        st.write("üìä Distribution des scores :", df_melted["Score"].value_counts())

        # Moyenne et fr√©quence par sous-th√®me
        subtheme_stats = df_melted.groupby("Sous-th√®me")["Score"].agg(["count", "mean"]).sort_values("mean", ascending=False)

        # Polarit√© & v√©racit√© (IA)
        df_polarite = analyser_par_batches(df_enriched, batch_size=1000, process_func=traiter_batch_polarite)


        # Fusion des infos
        merged_stats = subtheme_stats.merge(df_polarite, left_index=True, right_on="Sous-th√®me")
        merged_stats = merged_stats.set_index("Sous-th√®me")
        merged_stats["count"] = pd.to_numeric(merged_stats["count"], errors="coerce")
        merged_stats["mean"] = pd.to_numeric(merged_stats["mean"], errors="coerce")
        merged_stats = merged_stats.dropna(subset=["mean", "count"])

        # üîç Aper√ßu complet avant filtrage
        st.write("üìå Aper√ßu avant filtrage sur la v√©racit√©", merged_stats[["count", "mean", "Polarit√© estim√©e", "V√©racit√© polarit√©"]])
        st.write("üîç Distribution des v√©racit√©s :", merged_stats["V√©racit√© polarit√©"].value_counts())

        # ‚úÖ Extraire les vrais positifs/n√©gatifs
        filtered_stats = merged_stats[merged_stats["V√©racit√© polarit√©"].isin(["‚úÖ Vrai positif", "‚úÖ Vrai n√©gatif"])]

        if filtered_stats.empty:
            st.warning("‚ö†Ô∏è Aucun sous-th√®me avec une polarit√© jug√©e 'vrai positif' ou 'vrai n√©gatif'. V√©rifiez l'algorithme ou les seuils.")
            st.stop()

        nb_ambigus = len(merged_stats) - len(filtered_stats)
        st.info(f"{nb_ambigus} sous-th√®me(s) ambigus ont √©t√© exclus de l‚Äôanalyse des plus polarisants.")

        max_mean = filtered_stats["mean"].max()
        min_mean = filtered_stats["mean"].min()

        best_subs = filtered_stats[filtered_stats["mean"] == max_mean]
        worst_subs = filtered_stats[filtered_stats["mean"] == min_mean]
        if show_best_worst:
            st.markdown("### üèÖ Sous-th√®mes les plus polarisants (avec polarit√© IA)")

            # üíö Favorables
            st.success(f"üíö Moyenne MAX = {max_mean:.2f}")
            for name, row in best_subs.iterrows():
                st.markdown(f"- **{name}** ‚Äî {int(row['count'])} verbatims")
                st.markdown(f"  ‚Ü™Ô∏è Polarit√© : `{row['Polarit√© estim√©e']}` ‚Äî `{row['V√©racit√© polarit√©']}`")

            # üíî D√©favorables
            st.error(f"üíî Moyenne MIN = {min_mean:.2f}")
            for name, row in worst_subs.iterrows():
                st.markdown(f"- **{name}** ‚Äî {int(row['count'])} verbatims")
                st.markdown(f"  ‚Ü™Ô∏è Polarit√© : `{row['Polarit√© estim√©e']}` ‚Äî `{row['V√©racit√© polarit√©']}`")

        if show_subtheme_table:
            # üìä Export complet possible aussi
            st.markdown("### üìä Moyenne des notes globales par sous-th√®me")
            afficher_dataframe_propre(filtered_stats, cmap="RdYlGn")


        if show_distribution_chart:
            fig, ax = plt.subplots(figsize=(10, 4))
            df_melted["Score"].hist(bins=[1, 2, 3, 4, 5, 6], rwidth=0.8, align="left", ax=ax)
            ax.set_title("Distribution des notes globales (Score)")
            ax.set_xlabel("Note")
            ax.set_ylabel("Nombre de verbatims")
            st.pyplot(fig)

        def display_representative_verbatims(subtheme_label, label_text):
            st.markdown(f"#### {label_text}")
            subset = df_enriched[df_enriched[subtheme_label].notna()]
            subset = subset.sort_values("Note globale avis 1", ascending=(label_text == "üíî N√©gatif"))
            
            for i, v in subset.iterrows():
                st.markdown(f"- *{v['Verbatim public']}*")
                st.markdown(f"  ‚Ü™Ô∏è Note : **{v['Note globale avis 1']}**")
                try:
                    # Analyse IA brute
                    sentiment = analyser_sentiment(v["Verbatim complet"][:512])[0]
                    st.markdown(f"  üß† IA : `{sentiment['label']}` (score={sentiment['score']:.2f})")
                except:
                    st.markdown("  ‚ùå Erreur d‚Äôanalyse sentiment")

                st.markdown("---")

        if show_verbatims_examples:
            for name in best_subs.index:
                display_representative_verbatims(name, "\U0001F49A Positif")

            for name in worst_subs.index:
                display_representative_verbatims(name, "\U0001F494 N√©gatif")

        if show_profil_matrix:
            # üìà Matrice Profil x Sous-th√®me
            col_cat = "√ätes-vous venu :"
            if col_cat in df_enriched.columns:
                df_temp = df_enriched[[col_cat] + subtheme_cols].copy()
                mat = df_temp.groupby(col_cat)[subtheme_cols].mean().T

                st.markdown("### üîç Matrice `Profil √ó Sous-th√®mes`")
                afficher_dataframe_propre(mat.T, cmap="RdYlGn")  # .T si tu veux l‚Äôavoir en lignes

                fig, ax = plt.subplots(figsize=(min(15, len(mat.columns) * 1.5), len(mat) * 0.4 + 3))
                sns.heatmap(mat, cmap="RdYlGn", center=0, annot=True, fmt=".2f", ax=ax)
                st.pyplot(fig)
            else:
                st.warning("Colonne de profil non trouv√©e.")

        st.markdown("### üèÖ Sous-th√®mes les plus polarisants (avec polarit√© IA)")
        for name, row in best_subs.iterrows():
            st.markdown(f"- **{name}** ‚Äî {int(row['count'])} verbatims")
            st.markdown(f"  ‚Ü™Ô∏è Polarit√© : {row['Polarit√© estim√©e']} ‚Äî {row['V√©racit√© polarit√©']}")

        # ---- Options d‚Äôaffichage pour le graphe style maquette ----
        st.sidebar.markdown("### üó∫Ô∏è Graphe style maquette")
        show_corr_accel = st.sidebar.checkbox("Afficher Corr√©lation √ó Acc√©l√©ration", value=True)
        date_col_name = st.sidebar.text_input("Colonne de date (pour l'acc√©l√©ration)", value="Date avis")
        resample_freq = st.sidebar.selectbox("Granularit√© temps", ["W", "M", "D"], index=0)
        recent_k = st.sidebar.slider("Fen√™tre 'premi√®res occurrences' (p√©riodes)", 1, 12, 3)

        # Nouveaux contr√¥les pour l‚Äôaffichage
        use_interactive = st.sidebar.checkbox("Mode interactif (Plotly)", value=True)
        top_labels = st.sidebar.slider("Max labels visibles", 0, 50, 15)
        inclure_extremes = st.sidebar.checkbox("Toujours afficher les extr√™mes", value=True)

        # ---- Calcul + affichage ----
        if show_corr_accel:
            if date_col_name not in df_enriched.columns:
                st.info(f"‚ÑπÔ∏è Colonne de date '{date_col_name}' absente : acc√©l√©ration fix√©e √† 0 et pas d‚Äôalerte r√©cente.")
                date_arg = None
            else:
                date_arg = date_col_name

            stats_bulles = calculer_bulles_corr_accel(
                df_enriched=df_enriched,
                subtheme_cols=subtheme_cols,
                note_col="Note globale avis 1",
                date_col=date_arg,
                freq=resample_freq,
                recent_k_periods=recent_k
            )

            st.markdown("### üß≠ Corr√©lation √ó Acc√©l√©ration (taille = % d‚Äôoccurrences)")
            if use_interactive:
                tracer_bulles_corr_accel_plotly(stats_bulles, top_labels=top_labels, inclure_extremes=inclure_extremes)
            else:
                tracer_bulles_corr_accel(stats_bulles, top_labels=top_labels)





        # Export CSV - uniquement les sous-th√®mes filtr√©s (vrai positifs/n√©gatifs)
        cols_to_export = ["count", "mean", "Polarit√© estim√©e", "V√©racit√© polarit√©"]
        st.download_button("‚¨áÔ∏è T√©l√©charger les r√©sultats (subthemes_filtr√©s.csv)",
            filtered_stats[cols_to_export].to_csv().encode("utf-8"),
            file_name="subthemes_filtr√©s.csv", mime="text/csv")

        # Optionnel : Export complet incluant les ambigus
        st.download_button("‚¨áÔ∏è T√©l√©charger toutes les stats (incl. ambigus)",
            merged_stats[cols_to_export].to_csv().encode("utf-8"),
            file_name="subthemes_complets.csv", mime="text/csv")
    
        if st.button("üìù G√©n√©rer un rapport de synth√®se"):
            rapport = generer_rapport_openai(filtered_stats)
            if rapport:
                st.markdown("### üßæ Rapport de synth√®se")
                st.markdown(rapport)

                pdf_bytes = exporter_rapport_pdf(rapport)
                st.download_button(
                    label="‚¨áÔ∏è T√©l√©charger le rapport en PDF",
                    data=pdf_bytes,
                    file_name="rapport_synthese_verbatims.pdf",
                    mime="application/pdf"
                )


