import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re
import csv
from keybert import KeyBERT
from transformers import pipeline
from collections import Counter
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans


st.set_page_config(layout="wide")
st.title("üß† Analyse d'avis clients avec d√©tection automatique + KeyBERT")

# Upload du fichier
file = st.file_uploader("üìÅ T√©l√©versez un fichier CSV (avis clients)", type="csv")

if file:
    # Chargement des donn√©es
    df = pd.read_csv(file, sep=';', encoding='utf-8', quoting=csv.QUOTE_MINIMAL)
    df.columns = ['date_avis', 'date_fin_experience', 'profil_client', 'verbatim_public', 'verbatim_prive']
    df['texte_complet'] = (df['verbatim_public'].fillna('') + ' ' + df['verbatim_prive'].fillna('')).str.lower()
    df = df[df['texte_complet'].str.strip() != '']
    st.success(f"{len(df)} avis charg√©s.")

    # Analyse de sentiment avec BERT
    with st.spinner("üîç Analyse de sentiment avec BERT..."):
        analyzer = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")
        df['sentiment'] = df['texte_complet'].apply(lambda x: int(analyzer(x[:512])[0]['label'][0]))

    # Extraction de mots-cl√©s avec KeyBERT
    if st.checkbox("üß† Extraire automatiquement les mots-cl√©s avec KeyBERT"):
        with st.spinner("Chargement de KeyBERT..."):
            kw_model = KeyBERT(model='all-MiniLM-L6-v2')

        ngram_list = []
        for i, texte in enumerate(df['texte_complet'].head(50)):
            if texte.strip():
                keywords = kw_model.extract_keywords(texte, keyphrase_ngram_range=(1, 3), stop_words='french', top_n=3)
                kw_clean = [kw[0] for kw in keywords]
                df.at[i, 'keybert_keywords'] = ", ".join(kw_clean)
                ngram_list.extend(kw_clean)

        # Affichage
        st.subheader("üóùÔ∏è Mots-cl√©s extraits")
        st.dataframe(df[['texte_complet', 'keybert_keywords']].head(10))

        # Fr√©quences
        freq = Counter(ngram_list).most_common(10)
        df_keywords = pd.DataFrame(freq, columns=["mot-cl√©", "fr√©quence"]).set_index("mot-cl√©")
        st.bar_chart(df_keywords)

    # Graphique des sentiments
    st.subheader("üìä R√©partition des notes de sentiment")
    fig, ax = plt.subplots()
    sns.histplot(df['sentiment'], bins=5, kde=False, ax=ax)
    ax.set_title("Distribution des scores de sentiment")
    ax.set_xlabel("Score (1 √† 5)")
    st.pyplot(fig)

    # Export
    st.download_button("üì• T√©l√©charger les r√©sultats", df.to_csv(index=False).encode('utf-8'), "resultats.csv", "text/csv")

if st.checkbox("üß† Regrouper automatiquement les clients (clustering KMeans)"):
    st.subheader("üìå Profils types d√©tect√©s automatiquement")

    # √âtape 1 : vectorisation des textes

    
    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)

    X = vectorizer.fit_transform(df['texte_complet'])



    # √âtape 2 : clustering (ex: 5 clusters)
    n_clusters = st.slider("Nombre de profils √† d√©tecter", 2, 10, 5)
    model = KMeans(n_clusters=n_clusters, random_state=42)
    df['persona_auto'] = model.fit_predict(X)

    # Affichage des clusters
    st.write(df[['texte_complet', 'persona_auto']].head(10))

    # Statistiques par cluster
    st.subheader("üìà Sentiment moyen par persona d√©tect√©")
    stats = df.groupby("persona_auto")["sentiment"].mean().reset_index()
    fig, ax = plt.subplots()
    sns.barplot(data=stats, x="persona_auto", y="sentiment", ax=ax)
    ax.set_title("Sentiment moyen par persona d√©tect√©")
    st.pyplot(fig)